An *Infrastructure Manager* is responsible for deploying nodes. In most of the cases it knows how to launch a node
on a remote machine. For instance the SSH infrastructure manager connects via SSH to a remote machine and launches
nodes.

===== Default Infrastructure Manager

*Default infrastructure manager* is designed to be used with ProActive
agent. It cannot perform an automatic deployment but any users
(including an agent) can add already existing nodes into it. In order to
create a node source with this infrastructure, run the following
command:

    $ PROACTIVE_HOME/bin/proactive-client --createns defaultns -infrastructure org.ow2.proactive.resourcemanager.nodesource.infrastructure.DefaultInfrastructureManager rmURL

The only parameter to provide is the following one:

-   **rmURL** - the URL of the Resource Manager.

===== Local Infrastructure Manager

*Local Infrastructure Manager* can be used to start nodes locally, i.e,
on the host running the Resource Manager. In order to create a node
source with this infrastructure, run the following command:

    $ PROACTIVE_HOME/bin/proactive-client --createns localns -infrastructure org.ow2.proactive.resourcemanager.nodesource.infrastructure.LocalInfrastructure rmURL credentialsPath numberOfNodes timeout javaProperties

-   *rmURL* - URL of the Resource Manager server (can leave it empty to
    use default value, i.e, the URL of the Resource Manager you connect
    to)

-   *credentialsPath* - The absolute path of the credentials file used
    to set the provider of the nodes.

-   *numberOfNodes* - The number of nodes to deploy.

-   *timeout* - The length in ms after which one a node is not expected
    anymore.

-   *javaProperties* - The java properties to setup the ProActive
    environment for the nodes

===== SSH Infrastructure

This infrastructure allows to deploy nodes over SSH.
This infrastructure needs 10 arguments, described hereafter:

-   **RM URL** - The Resource Manager's URL that will be used by the
    deployed nodes to register by themselves.

-   **SSH Options** - Options you can pass to the SSHClient executable (
    -l inria to specify the user for instance )

-   **Java Path** - Path to the java executable on the remote hosts.

-   **Scheduling Path** - Path to the Scheduler installation
    directory on the remote hosts.

-   **Node Time Out** - A duration after which one the remote nodes are
    considered to be lost.

-   **Attempt** - The number of time the Resource Manager tries to
    acquire a node for which one the deployment fails before discarding
    it forever.

-   **Target OS** - One of 'LINUX', 'CYGWIN' or 'WINDOWS' depending on
    the machines' ( in Hosts List file ) operating system.

-   **Java Options** - Java options appended to the command used to
    start the node on the remote host.

-   **RM Credentials Path** - The absolute path of the 'rm.cred' file to
    make the deployed nodes able to register to the Resource Manager (
    config/authentication/rm.cred ).

-   **Hosts List** - Path to a file containing the hosts on which
    resources should be acquired. This file should contain one host per
    line, described as a host name or a public IP address, optionally
    followed by a positive integer describing the number of runtimes to
    start on the related host (default to 1 if not specified). Example:

        rm.example.com
        test.example.net 5
        192.168.9.10 2

===== CLI Infrastructure

This generic infrastructure allows to deploy nodes using deployment
script written in arbitrary language. The infrastructure just launches
this script and waits until the ProActive node is registered in the
Resource Manager. Command line infrastructure could be used when you
prefer to describe the deployment process using shell scripts instead of
Java. Script examples can be found in
+PROACTIVE_HOME/samples/scripts/deployment+. The deployment script has 4
parameters: +HOST_NAME+, +NODE_NAME+, +NODE_SOURCE_NAME+, +RM_URL+. The
removal script has 2 parameters: +HOST_NAME+ and +NODE_NAME+.

This infrastructure needs 7 arguments, described hereafter:

-   **RM URL** - The Resource Manager's URL that will be used by the
    deployed nodes to register by themselves.

-   **Interpreter** - Path to the script interpreter (bash by default).

-   **Deployment Script** - A script that launches a ProActive node and
    register it to the RM.

-   **Removal Script** - A script that removes the node from the
    Resource Manager.

-   **Hosts List** - Path to a file containing the hosts on which
    resources should be acquired. This file should contain one host per
    line, described as a host name or a public IP address, optionally
    followed by a positive integer describing the number of runtimes to
    start on the related host (default to 1 if not specified). Example:

        rm.example.com
        test.example.net 5
        192.168.9.10 2

-   **Node Time Out** - The length in ms after which one a node is not
    expected anymore.

-   **Max Deployment Failure** - the number of times the resource
    manager tries to relaunch the deployment script in case of failure.

===== EC2 Infrastructure

The Elastic Compute Cloud, aka *EC2*, is an Amazon Web Service, that
allows its users to use machines (instances) on demand on the cloud. An
EC2 instance is a Xen virtual machine, running on different kinds of
hardware, at different prices, but always paid by the hour, allowing
lots of flexibility. Being virtual machines, instances can be launched
using custom operating system images, called *AMI* (Amazon Machine
Image). For the Resource Manager to use EC2 instances as computing
nodes, a specific EC2 Infrastructure as well as AMI creation utilities
are provided.

To use the EC2 Infrastructure in the Resource Manager, proper Amazon
credentials are needed. This section describes briefly how to obtain
them, and how to use them to configure your environment.

1.  First, you need to create an AWS account at
    <http://aws.amazon.com/>.

2.  With your new AWS account, sign up for EC2 at
    <http://aws.amazon.com/ec2/>.

3.  Now, you need to obtain the credentials. http://aws.amazon.com[On the AWS website],
    point your browser to the _Your Web Services Account_ button, a drop
    down list displays. Click _View Access Key Identifiers_.

4.  Use this information to fill in the properties *AWS_AKEY* (Access
    Key), *AWS_SKEY* (Secret Key) and *AWS_USER* (numerical EC2 user
    ID) in the file located in */config/rm/deployment/ec2.properties*.
    Those thee parameters should never change, except if you need for
    some reason to handle multiple EC2 accounts. Other properties in the
    configuration file are:

    -   *AMI:* Defines which AMI will be deployed on instances. The
        value to provide is the unique AMI Id, ami-XXX. If no default
        value is provided, you need to find a public ProActive AMI
        corresponding to the release you are using.

    -   *INSTANCE_TYPE:* One of m1.small, m1.large, m1.xlarge,
        c1.medium, c1.xlarge, which defines what kind of hardware the
        instance will be running on. m1 instances are memory focused,
        whereas c1 instances are for more CPU intensive tasks. This
        property defaults is m1.small, the cheapest and slowest of all.
+
WARNING: Only m1.xlarge and c1.xlarge instances are able to launch
x86_64 AMI. When trying to run such AMI, if INSTANCE_TYPE is
not one of the xlarge, it will be forced to m1.xlarge. If you
want to control the cost of your instances, do not run x86_64
AMIs.
+
    -   *MAX_INST:* Sets a maximum number of instances that can be
        deployed simultaneously on this infrastructure, which is useful
        to control the cost of instances.

Using the Scheduler and the Resource Manager with an EC2 NodeSource
requires specific configuration. EC2 instances, indeed, are located on a
private network, behind a NAT device: this allows fast communications
between two EC2 instances, but this is an issue when using the RMI
protocol. The workaround is to use a PAMR router, or the HTTP protocol.

For that reason, the HTTP protocol is forced for communications going
from the RM to the EC2 nodes. On the other way, from EC2 to the RM,
using HTTP communications is also the simplest, also RMISSH is possible
but requires manual configuration for deploying RSA keys. To configure
your RM with HTTP, all you need to specify is a configuration file with
the following properties, for both Resource Manager *and* Scheduler.

``` {.xml}
<prop key="proactive.net.nolocal" value="true"/>
<prop key="proactive.communication.protocol" value="http" />
<prop key="proactive.http.port" value="PORT" />
<prop key="proactive.net.noprivate" value="true" />
<prop key="proactive.useIPaddress" value="true" />
```

Note that you need to specify a different port for both configurations.
Sample configurations can be found in */samples/ec2*.

Using this configuration, you can start a Resource Manager and a
Scheduler using the */bin/proactive-server* script. An EC2 NodeSource can
now be added using the command line interface of the Resource Manager:

    $ PROACTIVE_HOME/bin/proactive-client --createns ec2 -infrastructure org.ow2.proactive.resourcemanager.nodesource.infrastructure.EC2Infrastructure ./config/rm/deployment/ec2.properties rmURL RMCredentialsPath nodeHttpPort

You will need to specify:

-   **configurationFile** - EC2 configuration file such as
    */config/rm/deployment/ec2.properties*, which you should have filled
    with your AWS credentials beforehand.

-   **rmURL** - a fully qualified URL conforming to
    *protocol://IP:port/*, where IP is the public IP of the machine
    where the Resource Manager is launched. Protocol and port are
    mandatory, as these values will be used to configure the ProActive
    runtime of the EC2 instances at boot. It describes the protocol and
    port used for communications from the instance to the Resource
    Manager.

-   **RMCredentialsPath** - to register on the Resource Manager, nodes
    need these credentials to log in. That can be found in
    */config/authentication/login.cfg* when using default configuration.

-   **nodeHttpPort** - As stated before, the EC2 node will expose itself
    with the HTTP protocol. You can configure which port it will use.
    This is useful if the machine on which the RM is started has
    restrictive firewall rules for outgoing connections.

Once the Resource Manager is up and running with its EC2 NodeSource, new
jobs can be added by using */bin/proactive-client*, or the Scheduler
GUI.

===== Load Sharing Facility (LSF) infrastructure

This infrastructure knows how to acquire nodes from LSF by submitting a
corresponding job. It will be submitted through SSH from the RM to the
LSF server.

    $ PROACTIVE_HOME/bin/proactive-client --createns lsf -infrastructure org.ow2.proactive.resourcemanager.nodesource.infrastructure.LSFInfrastructure rmURL javaPath SSHOptions schedulingPath javaOptions maxNodes nodeTimeout LSFServer RMCredentialsPath bsubOptions

where:

-   **RMURL** - URL of the Resource Manager from the LSF nodes point of
  view - this is the URL the nodes will try to lookup when attempting
  to register to the RM after their creation.

-   **javaPath** - path to the java executable on the remote hosts (ie
  the LSF slaves).

-   **SSH Options** - Options you can pass to the SSHClient executable (
  -l inria to specify the user for instance )

-   **schedulingPath** - path to the Scheduling/RM installation
  directory on the remote hosts.

-   **javaOptions** - Java options appended to the command used to start
  the node on the remote host.

-   **maxNodes** - maximum number of nodes this infrastructure can
  simultaneously hold from the LSF server. That is useful considering
  that LSF does not provide a mechanism to evaluate the number of
  currently available or idle cores on the cluster. This can result to
  asking more resources than physically available, and waiting for the
  resources to come up for a very long time as the request would be
  queued until satisfiable.

-   **Node Time Out** - The length in ms after which one a node is not
  expected anymore.

-   **Server Name** - URL of the LSF server, which is responsible for
  acquiring LSF nodes. This server will be contacted by the Resource
  Manager through an SSH connection.

-   **RM Credentials Path** - Encrypted credentials file, as created by
  the create-cred[.bat] utility. These credentials will be used by the
  nodes to authenticate on the Resource Manager.

-   **Submit Job Opt** - Options for the bsub command client when
  acquiring nodes on the LSF master. Default value should be enough in
  most cases, if not, refer to the documentation of the LSF cluster.

===== Portable Batch System (PBS) infrastructure

This infrastructure knows how to acquire nodes from PBS (i.e. Torque) by
submitting a corresponding job. It will be submitted through SSH from
the RM to the PBS server.

    $ PROACTIVE_HOME/bin/proactive-client --createns pbs -infrastructure org.ow2.proactive.resourcemanager.nodesource.infrastructure.PBSInfrastructure rmURL javaPath SSHOptions schedulingPath javaOptions maxNodes nodeTimeout PBSServer RMCredentialsPath qsubOptions

where:

-   **RMURL** - URL of the Resource Manager from the PBS nodes point of
    view - this is the URL the nodes will try to lookup when attempting
    to register to the RM after their creation.

-   **javaPath** - path to the java executable on the remote hosts (ie
    the PBS slaves).

-   **SSH Options** - Options you can pass to the SSHClient executable (
    -l inria to specify the user for instance )

-   **schedulingPath** - path to the Scheduling/RM installation
    directory on the remote hosts.

-   **javaOptions** - Java options appended to the command used to start
    the node on the remote host.

-   **maxNodes** - maximum number of nodes this infrastructure can
    simultaneously hold from the PBS server. That is useful considering
    that PBS does not provide a mechanism to evaluate the number of
    currently available or idle cores on the cluster. This can result to
    asking more resources than physically available, and waiting for the
    resources to come up for a very long time as the request would be
    queued until satisfiable.

-   **Node Time Out** - The length in ms after which one a node is not
    expected anymore.

-   **Server Name** - URL of the PBS server, which is responsible for
    acquiring PBS nodes. This server will be contacted by the Resource
    Manager through an SSH connection.

-   **RM Credentials Path** - Encrypted credentials file, as created by
    the create-cred[.bat] utility. These credentials will be used by the
    nodes to authenticate on the Resource Manager.

-   **Submit Job Opt** - Options for the qsub command client when
    acquiring nodes on the PBS master. Default value should be enough in
    most cases, if not, refer to the documentation of the PBS cluster.


===== Generic Batch Job infrastructure

*Generic Batch Job infrastructure* provides users with the capability to
add the support of new batch job scheduler by providing a class
extending
org.ow2.proactive.resourcemanager.nodesource.infrastructure.BatchJobInfrastructure.
Once you have written that implementation, you can create a node source
which makes usage of this infrastructure by running the following
command:

    $ PROACTIVE_HOME/bin/proactive-client --createns pbs -infrastructure org.ow2.proactive.resourcemanager.nodesource.infrastructure.GenericBatchJobInfrastructure rmURL javaPath SSHOptions schedulingPath javaOptions maxNodes nodeTimeout BatchJobServer RMCredentialsPath subOptions implementationName implementationPath

where:

-   **RMURL** - URL of the Resource Manager from the batch job scheduler
    nodes point of view - this is the URL the nodes will try to lookup
    when attempting to register to the RM after their creation.

-   **javaPath** - path to the java executable on the remote hosts (ie
    the slaves of the batch job scheduler).

-   **SSH Options** - Options you can pass to the SSHClient executable (
    -l inria to specify the user for instance )

-   **schedulingPath** - path to the Scheduling/RM installation
    directory on the remote hosts.

-   **javaOptions** - Java options appended to the command used to start
    the node on the remote host.

-   **maxNodes** - maximum number of nodes this infrastructure can
    simultaneously hold from the batch job scheduler server.

-   **Node Time Out** - The length in ms after which one a node is not
    expected anymore.

-   **Server Name** - URL of the batch job scheduler server, which is
    responsible for acquiring nodes. This server will be contacted by
    the Resource Manager through an SSH connection.

-   **RM Credentials Path** - Encrypted credentials file, as created by
    the create-cred[.bat] utility. These credentials will be used by the
    nodes to authenticate on the Resource Manager.

-   **Submit Job Opt** - Options for the submit command client when
    acquiring nodes on the batch job scheduler master.

-   **implementationName** - Fully qualified name of the implementation
    of
    org.ow2.proactive.resourcemanager.nodesource.infrastructure.BatchJobInfrastructure
    provided by the end user.

-   **implementationPath** - The absolute path of the implementation of
    org.ow2.proactive.resourcemanager.nodesource.infrastructure.BatchJobInfrastructure.


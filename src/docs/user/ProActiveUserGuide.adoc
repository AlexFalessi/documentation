= ProActive User Guide
include::../common.adoc[]
:toc-title: User Guide
:imagesdir: src/docs/user/images

== Overview
*ProActive Scheduler* is a free and open-source *job scheduler*. The user specifies the computation that he/she desires in terms of series computation
 steps along with their execution and data dependencies. The scheduler executes this computation on a cluster
 of computation resources, each step on the best-fit resource and in parallel wherever its possible.

== Get started

To submit your first computation to *ProActive Scheduler* link:ProActiveAdminGuide.html#_getting_started[install] it in
your environment or just use our demo platform http://try.activeeon.com[try.activeeon.com^].

*ProActive Scheduler* provides comprehensive interfaces that allow to:

- http://try.activeeon.com/studio[Create workflows^]
- http://try.activeeon.com/scheduler[Submit workflows, monitor their execution and retrieve the tasks results^]
- http://try.activeeon.com/rm[Add resources and monitor them^]

We also provide REST and command line interfaces for advanced users.

== Create and run your computation

=== Jobs, workflows and tasks

In order to use Scheduler for executing various computations, one needs to write the execution definition
also known as the Workflow definition. A workflow definition is an XML file that adheres to XML schema for ProActive
Workflows.

It specifies a number of XML tags for specifying execution steps, their sequence and dependencies.
Each execution step corresponds to a task which is the smallest unit of execution that can be performed on a
 computation resources. There are several types of tasks which caters different use cases.

For instance, a script
task can be used to execute an inline script definition or a script file as an execution step whereas a
native task can be used to execute a native executable file. It also possible to package an workflow definition
along with its dependencies (libraries, executables etc) into a self-contained archive.

*ProActive Scheduler* currently supports three main types of tasks:

- +Native Task+, an executable with eventual parameters to be executed
- +Script Task+, a script writen in Groovy, Ruby, Python and other languages supported by the JSR-223
- +Java Task+, a task written in Java extending the Scheduler API

One can use **ProActive Workflow Studio**  to create and submit workflows graphically .
They can simply drag-and-drop various task constructs and draw their dependencies to form complex jobs.
It also provides various flow control widgets such as conditional branch, loop, replicate etc to construct complex workflows.

// TODO image workflow

In this tasks graph, we see that task 4 is preceded by task 1, that
means scheduler waits the end of task 1 execution before launching task
4. In a more concrete way, task 1 could be the calculation of a part of
the problem to solve, and task 4 takes result provided by task 1 and
compute another step of the calculation. We introduce here the concept
of **result passing** between tasks, explained later. This relation is
called a dependence, and we say that task 4 **depends** on task 1.

We see that task 1, 2 and 3 are not linked, so these three tasks can be
executed in **parallel**, because there are independent from each other.

Definition of the workflow graph is made at job definition, before
scheduling, and cannot be modified during the job execution.

A *finished job* contains the results and logs of each task. Upon failure,
a task can be restarted automatically or cancelled.

=== A simple example

The http://try.activeeon.com/tutorials/quickstart/quickstart.html[quickstart tutorial] on http://try.activeeon.com[try.activeeon.com]
shows you how to build a simple workflow using script tasks.

=== Native application

Using native tasks you can easily reuse existing applications and embed them in a workflow.
The Scheduler lets you define a native task that takes the name of the executable and list of parameters.
Once the executable is wrapped as a task you can easily leverage some of the workflow constructs to run your
executable in parallel.

TIP:  We advise you to test your application first, make sure that it works on a simple use on
one machine and then embed it in a workflow.

You can find an example of such integration in this
link:examples/native_task.xml[XML workflow^] or you can also build it yourself using the
*Workflow Studio*.

Native application by nature can be tied to a given operating system so
if you have different nodes at your disposal, you might need to select a suitable node to run your native task.
This can be achieved using selection script.
// TODO link

=== Dynamic language support

Proactive Scheduler supports tasks  written in languages other than Java, with the currently supported dynamic languages being
http://groovy.codehaus.org[Groovy^], http://www.jython.org[Python^], http://jruby.org[Ruby^] and
http://docs.oracle.com/javase/6/docs/technotes/guides/scripting/programmer_guide/#jsengine[Javascript^]
.

You can easily embed small scripts in your workflow.
The nice thing is that the workflow will be self containing and will not require to compile your code before executing. However we
recommend that you keep these scripts smalls to keep the workflow simple to understand.

TIP: Use scripts to print debugging statements when you build a new workflow.

Please note that the script execution relies on Java implementation of the cited languages thus it may come with
some limitations.

You can find an example of a script task in this
link:examples/script_task.xml[XML workflow^] or you can also build it yourself using the
*Workflow Studio*. The http://try.activeeon.com/tutorials/quickstart/quickstart.html[quickstart tutorial]
relies on script task and is a nice introduction to workflows.

Scripts can also be used to decorate tasks with specific actions, we support pre/post/clean/selection scripts.

=== MPI application

http://en.wikipedia.org/wiki/Message_Passing_Interface[MPI^] is often used in the area of parallel computing.
The Scheduler integrates with MPI with the concept of *multi node tasks*. This particular task will acquire several
nodes and will expose these nodes to the MPI environment.

Applications built with MPI are often executed using the http://linux.die.net/man/1/mpirun[mpirun^] command.
It accepts several parameters to
choose how many CPUs and how many machines will be used. One particular parameter is the machine file that is
built by the Scheduler when using *multi node tasks*.
Here is how a MPI application invocation would look like when executed with the Scheduler:

    mpirun -hostfile $PAS_NODESFILE myApplication

The variable +$PAS_NODESFILE+ contains the path to a machine file created by the Scheduler that will be similar to:

    compute-host
    compute-host
    another-host

Meaning that +myApplication+ will use 2 CPUs on +compute-host+ and 1 CPU on +another-host+.

You can find an example of a script task in this
link:examples/mpi_task.xml[XML workflow^] or you can also build it yourself using the
*Workflow Studio*.

To achieve the best performance for MPI applications nodes can be selected taking into account their *network topology*. One might want to select nodes that are as
close as possible to obtain better network performance or nodes on different hosts to split the I/O load.
// TODO link to ref

=== Run a workflow

To run a workflow, you submit it to *ProActive Scheduler*.
The submission will perform some verifications to ensure that a workflow is
correctly formed. Then, a job is created and inserted in the pending queue and
waits for executions until free resources become available. Once done,
the job will be started on the resources controlled by ProActive Resource
Manager. Finally, once finished, the job goes to the queue of finished
jobs and will wait until the user retrieves its result.

You can submit a workflow to the Scheduler using the *Workflow Studio*, the Scheduler Web interface or command
line tools. For advanced users we also expose REST and JAVA APIs.
// TODO link

TIP: During the submission, you will be able to edit workflow's variables, so you can effectively use
them to parametrize workflows executions and work with workflows as templates.
// TODO link

==== Job/Task states

During their execution, jobs and tasks goes through different states:

* +PENDING+: The job is waiting to be scheduled.
* +RUNNING+: The job is running. Actually at least one of its task has been scheduled.
* +STALLED+: The job has been launched but no task are currently running.
* +FINISHED+:The job is finished. Every tasks are finished.
* +PAUSED+: The job is paused waiting for user to resume it.
* +CANCELED+: The job has been canceled due to user exception and order.
This status runs when a user exception occurs in a task
and when the user has asked to cancel On exception.
* +FAILED+: The job has failed. One or more tasks have failed (due to resources failure).
There is no more executionOnFailure left for a task.
* +KILLED+: The job has been killed by a user.
Nothing can be done anymore on this job expect read execution information such as output, time, etc.

// TODO state diagram

==== Retrieve results

Once a job or a task is terminated, it is possible to get its result. You can only get the result of the job that you own.
Results can be retrieved using the Scheduler web interface or the command line tools.

Along with results you can also retrieve logs from the task executions (standard ouput and error output)
as well as Scheduler logs that provide debugging information.

NOTE: When running native application, the task result will be the exit code of the application. Results
usually makes more sens when using script or Java tasks.

== Data Management

Passing data between tasks
parameters / results
variable / properties (example: native task with env variables, using pre script XOR forkenv)
Input/Output data (introduce NFS, dataspaces, global and user spaces)
A job that reads data from files and outputs in a file

== Workflow concepts

Workflows comes with constructs that help you distribute your computation. The tutorial
http://try.activeeon.com/tutorials/adv.html[Advanced workflows^] is a nice introduction to workflows with
ProActive.

Three constructs are available:

- *Dependency*
- *Replicate*
- *Branch*
- *Loop*

TIP: Use the *Workflow Studio* to create complex workflows, it is much easier than to write XML!

=== Dependency

Dependencies can be set between tasks in a TaskFlow job. It provides a way to execute your tasks in a specified order,
but also to forward result of an ancestor task to its children as parameter. Dependency between tasks is then
both a temporal dependency and a data dependency.

image::dependency.png[align=center]

Dependencies between tasks can be added either in *ProActive Workflow Studio* or simply in workflow XML as shown below:

[source, xml]
----
<taskFlow>
    <task name="task1">
	    <javaExecutable class="MyTask1"/>
    </task>
    <task name="task2">
        <depends>
            <task ref="task1"/>
        </depends>
		<javaExecutable class="MyTask2"/>
    </task>
</taskFlow>
----

=== Replicate

The *replication* allows the execution of multiple tasks in parallel when only one task
is defined and the number of tasks to run could change.

image::flow_spec_duplicate.png[align=center]

-   The target is the direct child of the task initiator.

-   The initiator can have multiple children; each child is replicated.

-   If the target is a *start block*, the whole block is replicated.

-   The target must have the initiator as only dependency: the action is
    performed when the initiator task terminates. If the target has an
    other pending task as dependency, the behaviour cannot be specified.

-   There should always be a merge task after the target of a replicate:
    if the target is not a start block, it should have at least one
    child, if the target is a start block, the corresponding end block
    should have at least one child.

-   The last task of a replicated task block (or the replicated task if
    there is no block) cannot perform a *branching* or *replicate*
    action.

-   The target of a *replicate* action can not be tagged as *end block*.

TIP: If you are familiar with programming, you can see the replication as forking tasks.

=== Branch

The *branch* construct provides the ability to choose between two alternative task flows,
with the possibility to merge back to a common flow.

TIP: If you are a developer, you can see the replication as forking tasks

image::flow_spec_if.png[align=center]

-   There is no explicit dependency between the initiator and the
    *if/else* targets. These are *optional links* (ie. A -> B or E ->
    F) defined in the *if* task.

-   The *if* and *else* flows can be merged by a *continuation* task
    referenced in the *if* task, playing the role of an *endif*
    construct. After the branching task, the flow will either be that of
    the *if* or the *else* task, but it will be continued by the
    *continuation* task.

-   *If* and *else* targets are executed *exclusively*. The initiator
    however can be the dependency of other tasks, which will be executed
    normally along the *if* or the *else* target.

-   A *task block* can be defined across *if*, *else* and *continuation*
    links, and not just plain dependencies (i.e. with *A* as *start* and
    *F* as *end*).

-   If using no continuation task, the if and else targets, along with
    their children, must be strictly distinct.

-   If using a continuation task, the if and else targets must be
    strictly distinct and valid task blocks.

-   *if*, *else* and *continuation* tasks (B, D and F) cannot have
    an explicit dependency.

-   *if*, *else* and *continuation* tasks cannot be entry points for the
    job, they must be triggered by the *if* control flow action.

-   A task can be target of only one *if* or *else* action. A
    *continuation* task can not merge two different *if* actions.

TIP: If you are familiar with programming, you can see the branch as a if/then/else.

=== Loop

The loop provides the ability to repeat a set of tasks.

image::flow_spec_loop.png[align=center]

-   The target of a *loop* action must be a parent of the initiator
    following the dependency chain; this action goes back to a
    previously executed task.

-   Every task is executed at least once; *loop* operates in a
    *do...while* fashion.

-   The target of a *loop* should have only one explicit dependency. It
    will have different parameters (dependencies) depending if it is
    executed for the first time or not. The cardinality should stay the
    same.

-   The *loop* scope should be a *task block*: the target is a *start
    block* task, and the initiator its related *end block task*.

TIP: If you are familiar with programming, you can see the loop as a do/while.

=== Task Blocks

Workflows often relies on *task blocks*. Task blocks are defined by pairs of *start* and *end* tags.

-   Each task of the flow can be tagged either *start* or *end*

-   Tags can be nested

-   Each *start* tag needs to match a distinct *end* tag

Task blocks are very similar to the parenthesis of most programming
languages: anonymous and nested start/end tags. The only difference is
that a parenthesis is a syntactical information, whereas task blocks are
semantic.

The role of task blocks is to restrain the expressiveness of the system
so that a workflow can be statically checked and validated. A treatment
that can be looped or iterated will be isolated in a well-defined task
block.

-   A *loop* flow action only applies on a task block: the initiator of
 the loop must be the end of the block, and the target must be the
 beginning.

-   When using a *continuation* task in an *if* flow action, the *if*
 and *else* branches must be task blocks.

-   If the child of a *replicate* task is a task block, the whole block
 will be replicated and not only the child of the initiator.

=== Control Flow Scripts

To perform a control flow action such as if, replicate or loop, a
*Control Flow Script* is executed on the ProActive node. This script
takes the result of the task as input; meaning a Java object if it was a
Java or Script task, or nothing if it was a native task.

The script is executed on the ProActive node, just after the task's
executable. If the executable is a Java Executable and returns a result,
the variable +result+ will be set in the script's environment so that
dynamic decisions can be taken with the task's result as input. Native
Java objects can be used in a Javascript script using the following
syntax:

``` {.java}
importPackage(java.io);
// the result variable is the TaskResult.value() if it exists
var resFile = new File("/path/to/data/" + new java.lang.String(result));
if (! resFile.exists()) {
   loop = false;
} else {
   loop = true;
   var input = new BufferedReader(new FileReader(f));
   // this variable will determine the number of parallel runs
   runs = java.lang.Integer.parseInt(input.readLine());
   input.close()
}
```

Similarly to how parameters are passed through the *result* variable to
the script, the script needs to define variables specific to each action
to determine what action the script will lead to.

-   A *replicate* control flow action needs to define how many parallel
    runs will be executed, by defining the variable +runs+:

``` {.java}
// assuming result is a java.lang.Integer
runs = result % 4 + 1;
```

The assigned value needs be a strictly positive integer.

-   An *if* control flow action needs to determine whether the if or the
    else branch is selected, it does this by defining the boolean
    variable +branch+:

``` {.java}
// assuming result is a java.lang.Integer
if (result % 2) {
  branch = "if";
} else {
  branch = "else";
}
```

The assigned value needs to be the string value +"if"+ or +"else"+.

-   The *loop* control flow action requires setting the +loop+, which
    will determine whether looping to the statically defined target is
    performed, or if the normal flow is executed as would a continue
    instruction do in a programming language:

``` {.java}
loop = new java.lang.Boolean(result);
```

The assigned value needs to be a boolean.

Failure to set the required variables or to provide a valid
control flow script will not be treated gracefully and will result in
the failure of the task.

=== Loop and Replicate awareness

When Control Flow actions such as *replicate* or *loop* are performed,
some tasks are replicated. To be able to identify replicated tasks
uniquely, each replicated task has an *iteration index* and *replication
index*.

==== Task name

First, those indexes are reflected inside the names of the tasks
themselves. Indeed, task names must be unique inside a job. The indexes
are added to the original task name as a suffix, separated by a special
character.

-   If a task named _T_ is replicated after a *loop* action, the newly
    created tasks will be named _T#1_, _T#2_, etc. The number
    following the _#_ separator character represents the *iteration
    index*.

-   The same scheme is used upon *replicate* actions: newly created
    tasks are named _T*1_, _T*2_, and so on. The number following the
    \* separator represents the *replication index*.

-   When combining both of the above, the resulting task names are of
    the form: _T#1*1_, _T#2*4_, etc., in that precise order.

==== Task definition

Those indexes are also available when creating a task. They can be
obtained using a special string that will be substituted with the actual
iteration or replication index at runtime: *\$IT* for the iteration
index, and *\$REP* for the replication index. Those macro can be used in
the following locations:

-   *Java Executable parameters:*

    ``` {.xml}
    <javaExecutable class="net.example.Executable">
      <parameters>
        <parameter name="images" value="/some/path/images/pic_$IT_$REP.jpg" />
    ```

    ``` {.java}
    JavaTask t = new JavaTask();
    t.setExecutableClassName("net.example.Executable");
    t.addArgument("images","/some/path/images/pic_$IT_$REP.jpg");
    ```

-   *Native Executable arguments:*

    ``` {.xml}
    <staticCommand value="/path/to/bin.sh">
      <arguments>
        <argument value="/some/path/$IT/$REP.dat" />
    ```

    ``` {.java}
    NativeTask nt = new NativeTask();
    nt.setCommandLine(new String[] { "/path/to/bin.sh", "/path/to/$ID/$REP.dat" });
    ```

-   *Dataspace input and output:*

    ``` {.xml}
    <task name="t1" retries="2">
      <inputFiles>
        <files includes="foo_$IT_$REP.dat" accessMode="transferFromInputSpace"/>
      </inputFiles><outputFiles>
        <files includes="bar_$IT_$REP.res" accessMode="transferToOutputSpace"/>
    ```

    ``` {.java}
    task.addInputFiles("foo_$IT_$REP.dat",OutputAccessMode.TransferToOutputSpace);
    task.addOutputFiles("bar_$IT_$REP.res",OutputAccessMode.none);
    ```

-   *Script :*

    ``` {.xml}
    <task>
      <pre><script><code language="javascript">
            var f = new java.io.File(".lock_$IT_$REP");
            f.createNewFile();
      </code></script></pre>
    ```

    ``` {.java}
    task.setPreScript(new SimpleScript("var f = new java.io.File(\".lock_$ID_$REP\"); f.createNewFile();", "javascript"));
    ```

    Scripts affected by the macro substitution are: Pre, Post, Command
    generation and Control Flow. *No substitution will occur in
    selection scripts.*

==== Task executable

The iteration and replication indexes are available inside the
executables launched by tasks.

In Java tasks, the indexes are exported through the following Java
properties: *pas.task.iteration* and *pas.task.replication*.

``` {.java}
public Serializable execute(TaskResult... results) throws Throwable {
  int it  = System.getProperty("pas.task.iteration");
  int dup = System.getProperty("pas.task.replication");
}
```

In a similar fashion, environment variables are set when launching a
native executable: *PAS\_TASK\_ITERATION* and *PAS\_TASK\_REPLICATION*:

``` {.sh}
#!/bin/sh
/path/to/bin.sh /path/to/file/${PAS_TASK_ITERATION}/${PAS_TASK_REPLICATION}.dat

```


=== Example: Embarrassingly Parallel problem

 (Link to tutorial)


== Job/Task customization



=== Workflow scripts

==== Selection

==== Pre/Post/Clean

=== Control execution

==== Run computation on a particular node (Selection?)

==== Run computation with your system account

==== Reserve more than one node for a task (parallel environment)

==== Handling failures (retry on error, max number of exec, cancel on error, ...)

Planification

== Other

== Reference

=== Job and task specification

=== Scheduler Command line
include::./references/SchedulerCLI.adoc[]

